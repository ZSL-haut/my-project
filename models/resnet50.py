import os
import numpy as np
import pandas as pd
import torch
import torch.nn as nn
from torch.utils.data import Dataset, DataLoader
from PIL import Image
import torchvision.transforms as transforms
from sklearn.preprocessing import LabelEncoder
from collections import Counter
import torchvision.models as models
import matplotlib.pyplot as plt
from torch.optim.lr_scheduler import CosineAnnealingLR

# é…ç½®å‚æ•°
class Config:
    train_data_root = '../datas/datas1/train'
    val_data_root = '../datas/datas1/val'
    classes = ["å¾®å¸¦é’", "æ‚è‰²", "æŸ æª¬é»„", "æ©˜é»„", "çº¢æ£•", "é’è‰²"]
    image_size = (224, 224)
    batch_size = 32
    random_seed = 42
    max_npy_channels = 3
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    num_epochs = 100
    lr_pretrained = 5e-5
    lr_new = 1e-3
    weight_decay = 1e-4
    feature_dim = 512
    patience = 20
    output_dir = '../results/result1/resnet50'
    local_resnet_pretrained_path = '../pre_models/resnet50.pth'


def get_transforms():
    train_transform = transforms.Compose([
        transforms.RandomResizedCrop(Config.image_size, scale=(0.5, 1.0)),
        transforms.RandomHorizontalFlip(),
        transforms.RandomVerticalFlip(),
        transforms.ColorJitter(brightness=0.3, contrast=0.3, saturation=0.3, hue=0.1),
        transforms.RandomRotation(15),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
    ])
    test_transform = transforms.Compose([
        transforms.Resize(256),
        transforms.CenterCrop(Config.image_size),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
    ])
    return train_transform, test_transform


# è‡ªå®šä¹‰æ•°æ®é›†
class MultimodalDataset(Dataset):
    def __init__(self, file_pairs, transform=None, npy_transform=None):
        self.file_pairs = file_pairs
        self.transform = transform
        self.npy_transform = npy_transform

    def __len__(self):
        return len(self.file_pairs)

    def __getitem__(self, idx):
        img_path, npy_path, label = self.file_pairs[idx]
        img = Image.open(img_path).convert('RGB')
        if self.transform:
            img = self.transform(img)

        npy_data = np.load(npy_path).astype(np.float32)
        if npy_data.ndim == 2:
            npy_data = np.expand_dims(npy_data, axis=-1)

        current_channels = npy_data.shape[-1]
        if current_channels < Config.max_npy_channels:
            padded_data = np.zeros((*npy_data.shape[:2], Config.max_npy_channels), dtype=np.float32)
            padded_data[:, :, :current_channels] = npy_data
            npy_data = padded_data
        elif current_channels > Config.max_npy_channels:
            npy_data = npy_data[:, :, :Config.max_npy_channels]

        # Min-Max Normalization
        min_val = np.percentile(npy_data, 5)
        max_val = np.percentile(npy_data, 95)
        npy_range = max_val - min_val
        if npy_range < 1e-6:
            npy_data = np.zeros_like(npy_data) + 0.5
        else:
            npy_data = (npy_data - min_val) / npy_range
        npy_data = np.clip(npy_data, 0, 1)

        npy_data = torch.from_numpy(npy_data).permute(2, 0, 1).float()

        if self.npy_transform:
            npy_data = self.npy_transform(npy_data)

        label = torch.tensor(label, dtype=torch.long)
        return (img.float(), npy_data), label


def load_resnet_pretrained_weights(model, weight_path):
    """
    åŠ è½½ ResNet50 é¢„è®­ç»ƒæƒé‡çš„ä¸“ç”¨å‡½æ•°
    æ”¯æŒ .pth å’Œ .bin æ ¼å¼ï¼Œå¤„ç†é”®åä¸åŒ¹é…é—®é¢˜

    Args:
        model: PyTorch ResNet50 æ¨¡å‹å®ä¾‹
        weight_path: æƒé‡æ–‡ä»¶è·¯å¾„

    Returns:
        model: åŠ è½½æƒé‡åçš„æ¨¡å‹
    """
    print(f"\n{'=' * 100}")
    print(f"æ­£åœ¨åŠ è½½ ResNet50 é¢„è®­ç»ƒæƒé‡...")
    print(f"æƒé‡æ–‡ä»¶è·¯å¾„: {weight_path}")
    print(f"{'=' * 100}")

    if not os.path.exists(weight_path):
        print(f"âš ï¸  è­¦å‘Šï¼šæƒé‡æ–‡ä»¶ä¸å­˜åœ¨")
        print(f"   è·¯å¾„: {weight_path}")
        print(f"   å°†ä½¿ç”¨éšæœºåˆå§‹åŒ–æˆ–åœ¨çº¿ä¸‹è½½æƒé‡")
        return None

    try:
        # 1. åŠ è½½æƒé‡æ–‡ä»¶
        print(f"æ­£åœ¨è¯»å–æƒé‡æ–‡ä»¶...")
        checkpoint = torch.load(weight_path, map_location='cpu')
        print(f"âœ“ æƒé‡æ–‡ä»¶åŠ è½½æˆåŠŸ")

        # 2. æå– state_dict
        if isinstance(checkpoint, dict):
            # å°è¯•å¸¸è§çš„é”®å
            possible_keys = ['model', 'state_dict', 'model_state', 'net']
            state_dict = None

            for key in possible_keys:
                if key in checkpoint:
                    state_dict = checkpoint[key]
                    print(f"âœ“ ä» checkpoint['{key}'] æå– state_dict")
                    break

            if state_dict is None:
                # å‡è®¾ checkpoint æœ¬èº«å°±æ˜¯ state_dict
                state_dict = checkpoint
                print(f"âœ“ checkpoint æœ¬èº«å°±æ˜¯ state_dict")
        else:
            state_dict = checkpoint
            print(f"âœ“ checkpoint æœ¬èº«å°±æ˜¯ state_dict")

        # 3. æ‰“å°æƒé‡ä¿¡æ¯
        print(f"\næƒé‡æ–‡ä»¶ä¿¡æ¯:")
        print(f"  - åŒ…å«å‚æ•°æ•°é‡: {len(state_dict)}")
        sample_keys = list(state_dict.keys())[:5]
        print(f"  - ç¤ºä¾‹é”®å: {sample_keys}")

        # 4. è·å–æ¨¡å‹çš„ state_dict
        model_state_dict = model.state_dict()
        model_keys = list(model_state_dict.keys())
        print(f"\næ¨¡å‹ä¿¡æ¯:")
        print(f"  - æ¨¡å‹å‚æ•°æ•°é‡: {len(model_keys)}")
        print(f"  - ç¤ºä¾‹é”®å: {model_keys[:5]}")

        # 5. å°è¯•åŠ è½½ï¼ˆå…è®¸éƒ¨åˆ†åŒ¹é…ï¼‰
        print(f"\n{'â”€' * 100}")
        print(f"å¼€å§‹åŠ è½½æƒé‡...")
        missing_keys, unexpected_keys = model.load_state_dict(state_dict, strict=False)

        # 6. ç»Ÿè®¡åŒ¹é…æƒ…å†µ
        total_keys = len(model_keys)
        matched_keys = total_keys - len(missing_keys)
        match_ratio = (matched_keys / total_keys) * 100

        print(f"\n{'â”€' * 100}")
        print(f"ğŸ“Š æƒé‡åŠ è½½ç»Ÿè®¡:")
        print(f"  - æ¨¡å‹æ€»å‚æ•°: {total_keys}")
        print(f"  - âœ… æˆåŠŸåŒ¹é…: {matched_keys} ({match_ratio:.2f}%)")
        print(f"  - âŒ ç¼ºå¤±çš„é”®: {len(missing_keys)}")
        print(f"  - âš ï¸  å¤šä½™çš„é”®: {len(unexpected_keys)}")

        # 7. æ ¹æ®åŒ¹é…ç‡ç»™å‡ºè¯Šæ–­
        if match_ratio >= 95:
            print(f"\nâœ… é¢„è®­ç»ƒæƒé‡åŠ è½½å®Œç¾ï¼åŒ¹é…ç‡: {match_ratio:.2f}%")
            print(f"   æ¨¡å‹å·²æˆåŠŸåŠ è½½é¢„è®­ç»ƒæƒé‡ï¼Œå¯ä»¥å¼€å§‹è®­ç»ƒ")
        elif match_ratio >= 80:
            print(f"\nâœ… é¢„è®­ç»ƒæƒé‡åŠ è½½æˆåŠŸï¼åŒ¹é…ç‡: {match_ratio:.2f}%")
            print(f"   å¤§éƒ¨åˆ†æƒé‡å·²åŠ è½½ï¼Œå°‘æ•°å±‚ä½¿ç”¨éšæœºåˆå§‹åŒ–")
        elif match_ratio >= 50:
            print(f"\nâš ï¸  è­¦å‘Šï¼šé¢„è®­ç»ƒæƒé‡éƒ¨åˆ†åŠ è½½ï¼ŒåŒ¹é…ç‡: {match_ratio:.2f}%")
            print(f"   çº¦ä¸€åŠçš„æƒé‡è¢«åŠ è½½ï¼Œå»ºè®®æ£€æŸ¥æƒé‡æ–‡ä»¶")
        else:
            print(f"\nâŒ é”™è¯¯ï¼šæƒé‡åŒ¹é…ç‡è¿‡ä½ ({match_ratio:.2f}%)")
            print(f"   æƒé‡æ–‡ä»¶å¯èƒ½ä¸å…¼å®¹ï¼Œå»ºè®®ï¼š")
            print(f"   1. æ£€æŸ¥æƒé‡æ–‡ä»¶æ˜¯å¦æ˜¯ ResNet50")
            print(f"   2. ç¡®è®¤æƒé‡æ¥æºï¼ˆtorchvision/å…¶ä»–ï¼‰")
            print(f"   3. è€ƒè™‘ä½¿ç”¨ torchvision å®˜æ–¹é¢„è®­ç»ƒæƒé‡")

        # 8. å¦‚æœç¼ºå¤±é”®è¾ƒå°‘ï¼Œæ‰“å°è¯¦æƒ…
        if 0 < len(missing_keys) <= 20:
            print(f"\nç¼ºå¤±çš„é”®ï¼ˆè¿™äº›å±‚å°†ä½¿ç”¨éšæœºåˆå§‹åŒ–ï¼‰:")
            for i, key in enumerate(missing_keys[:10], 1):
                print(f"   {i}. {key}")
            if len(missing_keys) > 10:
                print(f"   ... è¿˜æœ‰ {len(missing_keys) - 10} ä¸ª")

        # 9. å¦‚æœæœ‰å¤šä½™çš„é”®ä¸”æ•°é‡ä¸å¤šï¼Œæ‰“å°éƒ¨åˆ†
        if 0 < len(unexpected_keys) <= 20:
            print(f"\nå¤šä½™çš„é”®ï¼ˆæƒé‡æ–‡ä»¶ä¸­å­˜åœ¨ä½†æ¨¡å‹ä¸éœ€è¦ï¼‰:")
            for i, key in enumerate(unexpected_keys[:10], 1):
                print(f"   {i}. {key}")
            if len(unexpected_keys) > 10:
                print(f"   ... è¿˜æœ‰ {len(unexpected_keys) - 10} ä¸ª")

        print(f"{'=' * 100}\n")
        return model

    except Exception as e:
        print(f"\nâŒ åŠ è½½æƒé‡å¤±è´¥: {e}")
        print(f"é”™è¯¯è¯¦æƒ…:")
        import traceback
        traceback.print_exc()
        print(f"\nå°†ä½¿ç”¨éšæœºåˆå§‹åŒ–æˆ–åœ¨çº¿ä¸‹è½½æƒé‡ç»§ç»­")
        print(f"{'=' * 100}\n")
        return None


# æ”¹è¿›çš„å¤šæ¨¡æ€æ¨¡å‹
class ImprovedMultimodalResNet(nn.Module):
    def __init__(self, num_classes, pretrained_path=None):
        super().__init__()

        print(f"\n{'=' * 100}")
        print("åˆå§‹åŒ– ResNet50 å¤šæ¨¡æ€æ¨¡å‹")
        print(f"{'=' * 100}\n")

        # 1. åˆ›å»º ResNet50 æ¨¡å‹ï¼ˆä¸åŠ è½½é¢„è®­ç»ƒæƒé‡ï¼‰
        print("åˆ›å»º ResNet50 æ¨¡å‹ç»“æ„...")
        self.img_resnet = models.resnet50(weights=None)
        print("âœ“ æ¨¡å‹ç»“æ„åˆ›å»ºæˆåŠŸ")

        # 2. å°è¯•åŠ è½½æœ¬åœ°é¢„è®­ç»ƒæƒé‡
        weights_loaded = False
        if pretrained_path and os.path.exists(pretrained_path):
            result = load_resnet_pretrained_weights(self.img_resnet, pretrained_path)
            if result is not None:
                weights_loaded = True

        # 3. å¦‚æœæœ¬åœ°æƒé‡åŠ è½½å¤±è´¥ï¼Œå°è¯•åœ¨çº¿ä¸‹è½½
        if not weights_loaded:
            print(f"\n{'=' * 100}")
            print("âš ï¸  æœ¬åœ°é¢„è®­ç»ƒæƒé‡æœªæˆåŠŸåŠ è½½")
            if pretrained_path:
                print(f"   è·¯å¾„: {pretrained_path}")
            print("   å°è¯•ä½¿ç”¨ torchvision åœ¨çº¿é¢„è®­ç»ƒæƒé‡...")
            try:
                self.img_resnet = models.resnet50(weights=models.ResNet50_Weights.IMAGENET1K_V1)
                print("âœ… ä½¿ç”¨ torchvision ImageNet é¢„è®­ç»ƒæƒé‡")
                weights_loaded = True
            except Exception as e:
                print(f"âŒ åœ¨çº¿ä¸‹è½½ä¹Ÿå¤±è´¥: {e}")
                print("   å°†ä½¿ç”¨éšæœºåˆå§‹åŒ–ï¼ˆä¸æ¨èï¼Œè®­ç»ƒæ•ˆæœä¼šè¾ƒå·®ï¼‰")
            print(f"{'=' * 100}\n")

        # 4. é…ç½®å‚æ•°å†»ç»“ç­–ç•¥
        print("é…ç½®æ¨¡å‹å‚æ•°å†»ç»“ç­–ç•¥...")
        total_params = sum(p.numel() for p in self.img_resnet.parameters())

        # å†»ç»“å¤§éƒ¨åˆ†å‚æ•°
        for param in self.img_resnet.parameters():
            param.requires_grad = False

        # è§£å†» layer4ï¼ˆæœ€åä¸€ä¸ªæ®‹å·®å—ï¼‰
        for param in self.img_resnet.layer4.parameters():
            param.requires_grad = True

        trainable_params = sum(p.numel() for p in self.img_resnet.parameters() if p.requires_grad)
        frozen_params = total_params - trainable_params

        print(f"âœ“ ResNet50 å‚æ•°é…ç½®:")
        print(f"  - æ€»å‚æ•°: {total_params:,}")
        print(f"  - å¯è®­ç»ƒå‚æ•°: {trainable_params:,} ({trainable_params / total_params * 100:.1f}%)")
        print(f"  - å†»ç»“å‚æ•°: {frozen_params:,} ({frozen_params / total_params * 100:.1f}%)")

        # 5. æ›¿æ¢åˆ†ç±»å¤´
        num_ftrs = self.img_resnet.fc.in_features
        self.img_resnet.fc = nn.Identity()
        print(f"âœ“ ResNet50 ç‰¹å¾ç»´åº¦: {num_ftrs}")

        # 6. NPY ç‰¹å¾æå–å™¨
        self.npy_feature_extractor = nn.Sequential(
            nn.Conv2d(Config.max_npy_channels, 64, kernel_size=3, padding=1),
            nn.BatchNorm2d(64),
            nn.ReLU(inplace=True),
            nn.MaxPool2d(2),

            nn.Conv2d(64, 128, kernel_size=3, padding=1),
            nn.BatchNorm2d(128),
            nn.ReLU(inplace=True),
            nn.AdaptiveAvgPool2d(1)
        )
        print(f"âœ“ NPY ç‰¹å¾æå–å™¨åˆ›å»ºæˆåŠŸ (è¾“å‡ºç»´åº¦: 128)")

        # 7. åˆ†ç±»å™¨
        self.classifier = nn.Sequential(
            nn.Linear(num_ftrs + 128, 512),
            nn.BatchNorm1d(512),
            nn.ReLU(),
            nn.Dropout(0.5),
            nn.Linear(512, num_classes)
        )

        classifier_params = sum(p.numel() for p in self.classifier.parameters())
        npy_params = sum(p.numel() for p in self.npy_feature_extractor.parameters())

        print(f"âœ“ å¤šæ¨¡æ€èåˆåˆ†ç±»å™¨åˆ›å»ºæˆåŠŸ")
        print(f"  - è¾“å…¥ç»´åº¦: {num_ftrs + 128} (å›¾åƒ {num_ftrs} + NPY 128)")
        print(f"  - è¾“å‡ºç±»åˆ«æ•°: {num_classes}")
        print(f"  - åˆ†ç±»å™¨å‚æ•°: {classifier_params:,}")
        print(f"  - NPY æå–å™¨å‚æ•°: {npy_params:,}")
        print(f"\n{'=' * 100}\n")

    def forward(self, x):
        img, npy = x
        img_feat = self.img_resnet(img)
        npy_feat = self.npy_feature_extractor(npy)
        npy_feat = torch.flatten(npy_feat, 1)
        combined = torch.cat([img_feat, npy_feat], dim=1)
        return self.classifier(combined)


def load_data_from_folder(data_dir, classes):
    """Scans a directory to find image-npy pairs for each class."""
    file_pairs = []
    labels_text = []
    print(f"Scanning directory: {data_dir}")
    for class_name in classes:
        class_dir = os.path.join(data_dir, class_name)
        if not os.path.isdir(class_dir):
            print(f"Warning: Class directory not found, skipping: {class_dir}")
            continue
        for file in os.listdir(class_dir):
            if file.lower().endswith((".png", ".jpg", ".jpeg")):
                base_name = os.path.splitext(file)[0]
                img_path = os.path.join(class_dir, file)
                npy_path = os.path.join(class_dir, f"{base_name}.npy")
                if os.path.exists(npy_path):
                    file_pairs.append((img_path, npy_path))
                    labels_text.append(class_name)
    if not file_pairs:
        raise ValueError(f"No matching image/npy file pairs found in {data_dir}.")
    return file_pairs, labels_text


def plot_training_metrics(train_losses, train_accs, val_losses, val_accs, save_path):
    plt.figure(figsize=(12, 5))
    plt.subplot(1, 2, 1)
    plt.plot(train_losses, label='Training Loss')
    plt.plot(val_losses, label='Validation Loss')
    plt.title('Training & Validation Loss')
    plt.xlabel('Epoch')
    plt.ylabel('Loss')
    plt.legend()
    plt.grid(True)

    plt.subplot(1, 2, 2)
    plt.plot(train_accs, label='Training Accuracy')
    plt.plot(val_accs, label='Validation Accuracy')
    plt.title('Training & Validation Accuracy')
    plt.xlabel('Epoch')
    plt.ylabel('Accuracy')
    plt.legend()
    plt.grid(True)

    plt.tight_layout()
    plt.savefig(save_path)
    plt.close()


def train_model():
    os.makedirs(Config.output_dir, exist_ok=True)

    train_pairs, train_labels_text = load_data_from_folder(Config.train_data_root, Config.classes)
    val_pairs, val_labels_text = load_data_from_folder(Config.val_data_root, Config.classes)

    label_encoder = LabelEncoder()
    label_encoder.fit(Config.classes)
    train_labels = label_encoder.transform(train_labels_text)
    val_labels = label_encoder.transform(val_labels_text)

    print("\n--- Data Summary ---")
    print(f"Training samples: {len(train_labels)}")
    print("Training class distribution:", Counter(train_labels_text))
    print(f"Validation samples: {len(val_labels)}")
    print("Validation class distribution:", Counter(val_labels_text))
    print("---------------------\n")

    train_transform, test_transform = get_transforms()
    npy_transform = transforms.Compose([
        transforms.Resize(Config.image_size, antialias=True)
    ])

    train_data = [(p[0], p[1], lbl) for p, lbl in zip(train_pairs, train_labels)]
    val_data = [(p[0], p[1], lbl) for p, lbl in zip(val_pairs, val_labels)]

    train_dataset = MultimodalDataset(train_data, transform=train_transform, npy_transform=npy_transform)
    val_dataset = MultimodalDataset(val_data, transform=test_transform, npy_transform=npy_transform)

    train_loader = DataLoader(train_dataset, batch_size=Config.batch_size, shuffle=True, num_workers=4, pin_memory=True)
    val_loader = DataLoader(val_dataset, batch_size=Config.batch_size, num_workers=4, pin_memory=True)

    # ===== ä¿®æ”¹è¿™é‡Œï¼šä½¿ç”¨æ­£ç¡®çš„é¢„è®­ç»ƒæ¨¡å‹è·¯å¾„ =====
    model = ImprovedMultimodalResNet(
        len(Config.classes),
        pretrained_path=Config.local_resnet_pretrained_path  # ä½¿ç”¨ Config ä¸­å®šä¹‰çš„è·¯å¾„
    ).to(Config.device)

    class_counts = np.bincount(train_labels)
    class_weights = torch.tensor(1.0 / (class_counts + 1e-5), dtype=torch.float32).to(Config.device)
    criterion = nn.CrossEntropyLoss(weight=class_weights)

    optimizer = torch.optim.AdamW([
        {'params': [p for p in model.img_resnet.parameters() if p.requires_grad],
         'lr': Config.lr_pretrained, 'weight_decay': Config.weight_decay},
        {'params': model.npy_feature_extractor.parameters(),
         'lr': Config.lr_new, 'weight_decay': Config.weight_decay},
        {'params': model.classifier.parameters(),
         'lr': Config.lr_new, 'weight_decay': Config.weight_decay}
    ])

    scheduler = CosineAnnealingLR(optimizer, T_max=Config.num_epochs, eta_min=1e-7)

    training_history = []
    best_val_acc = 0
    no_improve_epoch = 0

    print("=" * 100)
    print("--- Starting Training ---")
    print("=" * 100 + "\n")

    for epoch in range(Config.num_epochs):
        model.train()
        total_loss, correct, total_samples = 0, 0, 0
        for batch_idx, ((img, npy), labels) in enumerate(train_loader):
            img, npy, labels = img.to(Config.device), npy.to(Config.device), labels.to(Config.device)
            optimizer.zero_grad()
            outputs = model((img, npy))
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item() * img.size(0)
            correct += (outputs.argmax(1) == labels).sum().item()
            total_samples += img.size(0)

        epoch_loss = total_loss / total_samples
        epoch_acc = correct / total_samples

        model.eval()
        val_correct, val_total_loss, val_total_samples = 0, 0, 0
        with torch.no_grad():
            for (img, npy), labels in val_loader:
                img, npy, labels = img.to(Config.device), npy.to(Config.device), labels.to(Config.device)
                outputs = model((img, npy))
                val_total_loss += criterion(outputs, labels).item() * img.size(0)
                val_correct += (outputs.argmax(1) == labels).sum().item()
                val_total_samples += img.size(0)

        val_loss = val_total_loss / val_total_samples
        val_acc = val_correct / val_total_samples

        scheduler.step()

        current_lr = optimizer.param_groups[1]['lr']

        print(f"Epoch {epoch + 1}/{Config.num_epochs} | "
              f"Train Loss: {epoch_loss:.4f} | Train Acc: {100 * epoch_acc:.2f}% | "
              f"Val Loss: {val_loss:.4f} | Val Acc: {100 * val_acc:.2f}% | "
              f"LR: {current_lr:.2e}")

        log_entry = {
            'epoch': epoch + 1,
            'train_loss': round(epoch_loss, 5),
            'train_accuracy': round(epoch_acc, 5),
            'val_loss': round(val_loss, 5),
            'val_accuracy': round(val_acc, 5),
            'learning_rate': current_lr
        }
        training_history.append(log_entry)

        if val_acc > best_val_acc:
            best_val_acc = val_acc
            torch.save(model.state_dict(), os.path.join(Config.output_dir, 'model.pth'))
            print(f"  -> New best model saved with accuracy: {100 * best_val_acc:.2f}%")
            no_improve_epoch = 0
        else:
            no_improve_epoch += 1

        if no_improve_epoch >= Config.patience:
            print(f"\nValidation accuracy did not improve for {Config.patience} epochs. Early stopping.")
            break

    print("\n" + "=" * 100)
    print("--- Training Finished ---")
    print("=" * 100 + "\n")

    history_df = pd.DataFrame(training_history)
    csv_path = os.path.join(Config.output_dir, 'training_log_resnet50.csv')
    history_df.to_csv(csv_path, index=False)
    print(f"Training log saved to: {csv_path}")

    plot_path = os.path.join(Config.output_dir, 'training_metrics_resnet50.png')
    plot_training_metrics(
        history_df['train_loss'], history_df['train_accuracy'],
        history_df['val_loss'], history_df['val_accuracy'],
        save_path=plot_path
    )
    print(f"Training plot saved to: {plot_path}")


if __name__ == "__main__":
    torch.manual_seed(Config.random_seed)
    np.random.seed(Config.random_seed)
    train_model()