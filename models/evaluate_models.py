import os
import numpy as np
import pandas as pd
import torch
import torch.nn as nn
from torch.utils.data import Dataset, DataLoader
from PIL import Image
import torchvision.transforms as transforms
from sklearn.preprocessing import LabelEncoder
from collections import Counter
import torchvision.models as models
from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score
import matplotlib.pyplot as plt
from matplotlib.backends.backend_pdf import PdfPages
import matplotlib
import glob

# ä½¿ç”¨Aggåç«¯ä»¥æ”¯æŒéäº¤äº’å¼ç¯å¢ƒä¸‹çš„ç»˜å›¾
matplotlib.use('Agg')

# å°è¯•å¯¼å…¥ timm åº“
try:
    import timm
except ImportError:
    timm = None


class Config:
    test_data_root = r"F:\çƒŸè‰é¡¹ç›®äºŒæœŸ\datas6\test"
    classes = ["æµ“", "å¼º", "ä¸­", "å¼±", "æ·¡"]
    image_size = (224, 224)
    batch_size = 32
    random_seed = 42
    max_npy_channels = 6
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    feature_dim = 512
    # ç»“æœä¿å­˜è·¯å¾„
    results_save_dir = './results/result6/unified_metrics'
    # è®­ç»ƒå¥½çš„æ¨¡å‹æƒé‡è·¯å¾„
    best_model_paths = {
        'convnext_tiny': './results/result6/convnext_tiny/best_model_convnext_tiny.pth',
        'efficientnet_b0': './results/result6/efficientnet_b0/best_model_efficientnet_b0.pth',
        'resnet34': './results/result6/ResNet34/best_model_resnet34.pth',
        'resnet50': './results/result6/ResNet50/best_model_resnet50.pth',
        'vit_base_patch16_224': './results/result6/vit_base_patch16_224/best_model_vit_base_patch16_224.pth',
        'swin_tiny_patch4_window7_224': './results/result6/swin_tiny_patch4_window7_224/best_model_swin_tiny_patch4_window7_224.pth'
    }

    # é¢„è®­ç»ƒæ¨¡å‹è·¯å¾„
    local_pretrained_paths = {
        'resnet34': "./pre_models/resnet34.pth",
        'resnet50': "./pre_models/resnet50.pth",
        'efficientnet_b0': "./pre_models/efficientnet_b0.bin",
        'vit_base_patch16_224': "./pre_models/vit_base_patch16_224.bin",
        'swin_tiny_patch4_window7_224': "./pre_models/swin_tiny_patch4_window7_224.bin",
        'convnext_tiny': "./pre_models/convnext_tiny.bin",
    }


# åˆ›å»ºç»“æœä¿å­˜ç›®å½•
os.makedirs(Config.results_save_dir, exist_ok=True)


def get_transforms():
    train_transform = transforms.Compose([
        transforms.RandomResizedCrop(Config.image_size, scale=(0.5, 1.0)),
        transforms.RandomHorizontalFlip(),
        transforms.RandomVerticalFlip(),
        transforms.ColorJitter(brightness=0.3, contrast=0.3, saturation=0.3, hue=0.1),
        transforms.RandomRotation(15),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
    ])
    test_transform = transforms.Compose([
        transforms.Resize(256),
        transforms.CenterCrop(Config.image_size),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
    ])
    return train_transform, test_transform


class MultimodalDataset(Dataset):
    def __init__(self, file_pairs, transform=None, npy_transform=None):
        self.file_pairs = file_pairs
        self.transform = transform
        self.npy_transform = npy_transform

    def __len__(self):
        return len(self.file_pairs)

    def __getitem__(self, idx):
        img_path, npy_path, label = self.file_pairs[idx]
        img = Image.open(img_path).convert('RGB')
        if self.transform:
            img = self.transform(img)

        npy_data = np.load(npy_path).astype(np.float32)

        if npy_data.ndim == 2:
            npy_data = np.expand_dims(npy_data, axis=-1)

        current_channels = npy_data.shape[-1]
        if current_channels < Config.max_npy_channels:
            padded_data = np.zeros((*npy_data.shape[:2], Config.max_npy_channels), dtype=np.float32)
            padded_data[:, :, :current_channels] = npy_data
            npy_data = padded_data
        elif current_channels > Config.max_npy_channels:
            npy_data = npy_data[:, :, :Config.max_npy_channels]

        min_val = np.percentile(npy_data, 5)
        max_val = np.percentile(npy_data, 95)
        npy_range = max_val - min_val
        if npy_range < 1e-6:
            npy_data = np.zeros_like(npy_data) + 0.5
        else:
            npy_data = (npy_data - min_val) / npy_range
        npy_data = np.clip(npy_data, 0, 1)

        npy_data = torch.from_numpy(npy_data).permute(2, 0, 1).float()

        if self.npy_transform:
            npy_data = self.npy_transform(npy_data)

        label = torch.tensor(label, dtype=torch.long)
        return (img.float(), npy_data), label


class ImprovedMultimodalModel(nn.Module):
    def __init__(self, num_classes, backbone_name='resnet34', local_pretrained_path=None):
        super().__init__()
        self.backbone_name = backbone_name
        self.img_backbone, self.feature_dim_img = self._get_image_backbone(backbone_name, local_pretrained_path)
        self.npy_feature_extractor = nn.Sequential(
            nn.Conv2d(Config.max_npy_channels, 64, kernel_size=3, padding=1),
            nn.BatchNorm2d(64),
            nn.ReLU(inplace=True),
            nn.MaxPool2d(2),
            nn.Conv2d(64, 128, kernel_size=3, padding=1),
            nn.BatchNorm2d(128),
            nn.ReLU(inplace=True),
            nn.MaxPool2d(2),
            nn.Conv2d(128, Config.feature_dim, kernel_size=3, padding=1),
            nn.BatchNorm2d(Config.feature_dim),
            nn.ReLU(inplace=True),
            nn.AdaptiveAvgPool2d(1)
        )
        self.feature_dim_npy = Config.feature_dim
        self.classifier = nn.Sequential(
            nn.Linear(self.feature_dim_img + self.feature_dim_npy, 512),
            nn.BatchNorm1d(512),
            nn.ReLU(),
            nn.Dropout(0.5),
            nn.Linear(512, num_classes)
        )

    def _get_image_backbone(self, backbone_name, local_pretrained_path):
        model = None
        feature_dim = 0

        if backbone_name.lower() == 'resnet34':
            model = models.resnet34(weights=None)
            feature_dim = model.fc.in_features
            model.fc = nn.Identity()
        elif backbone_name.lower() == 'resnet50':
            model = models.resnet50(weights=None)
            feature_dim = model.fc.in_features
            model.fc = nn.Identity()
        elif backbone_name.lower() == 'efficientnet_b0' and timm:
            model = timm.create_model('efficientnet_b0', pretrained=False)
            feature_dim = model.classifier.in_features
            model.classifier = nn.Identity()
        elif backbone_name.lower() == 'vit_base_patch16_224' and timm:
            model = timm.create_model('vit_base_patch16_224', pretrained=False)
            feature_dim = model.head.in_features
            model.head = nn.Identity()
        elif backbone_name.lower() == 'swin_tiny_patch4_window7_224' and timm:
            model = timm.create_model('swin_tiny_patch4_window7_224', pretrained=False)
            feature_dim = model.head.in_features
            model.head = nn.Identity()
        elif backbone_name.lower() == 'convnext_tiny' and timm:
            model = timm.create_model('convnext_tiny', pretrained=False)
            feature_dim = model.head.fc.in_features
            model.head.fc = nn.Identity()
        else:
            raise ValueError(f"Unsupported backbone name: {backbone_name}")

        return model, feature_dim

    def forward(self, x):
        img, npy = x
        img_feat = self.img_backbone(img)
        if img_feat.ndim == 3 and (self.backbone_name.startswith('vit') or self.backbone_name.startswith('swin')):
            img_feat = img_feat[:, 0]
        elif img_feat.ndim > 2:
            img_feat = torch.flatten(img_feat, 1)

        npy_feat = self.npy_feature_extractor(npy)
        npy_feat = torch.flatten(npy_feat, 1)

        combined = torch.cat([img_feat, npy_feat], dim=1)
        return self.classifier(combined)


def load_data_from_folder(data_dir, classes):
    """
    Scans a directory to find image-npy pairs for each class.
    å¢å¼ºç‰ˆï¼šæä¾›è¯¦ç»†çš„è°ƒè¯•ä¿¡æ¯ï¼Œå¤„ç†è·¯å¾„ç¼–ç é—®é¢˜
    """
    file_pairs = []
    labels_text = []

    print(f"\n{'=' * 80}")
    print(f"æ­£åœ¨æ‰«ææµ‹è¯•æ•°æ®ç›®å½•: {data_dir}")
    print(f"{'=' * 80}")

    # é¦–å…ˆæ£€æŸ¥æ ¹ç›®å½•æ˜¯å¦å­˜åœ¨
    if not os.path.exists(data_dir):
        raise ValueError(f"âŒ é”™è¯¯ï¼šæµ‹è¯•æ•°æ®æ ¹ç›®å½•ä¸å­˜åœ¨: {data_dir}")

    # è·å–ç›®å½•ä¸‹çš„æ‰€æœ‰å­ç›®å½•
    try:
        all_subdirs = [d for d in os.listdir(data_dir) if os.path.isdir(os.path.join(data_dir, d))]
        print(f"âœ“ æ‰¾åˆ° {len(all_subdirs)} ä¸ªå­ç›®å½•: {all_subdirs}")
    except Exception as e:
        raise ValueError(f"âŒ æ— æ³•è¯»å–ç›®å½• {data_dir}: {e}")

    # æ£€æŸ¥æ¯ä¸ªæœŸæœ›çš„ç±»ç›®å½•
    found_classes = []
    for class_name in classes:
        class_dir = os.path.join(data_dir, class_name)

        print(f"\n{'â”€' * 80}")
        print(f"ğŸ“ æ£€æŸ¥ç±»ç›®å½•: {class_name}")
        print(f"   å®Œæ•´è·¯å¾„: {class_dir}")

        # ä½¿ç”¨ os.path.exists æ£€æŸ¥ç›®å½•æ˜¯å¦å­˜åœ¨
        if not os.path.exists(class_dir):
            print(f"   âš ï¸  è­¦å‘Šï¼šç›®å½•ä¸å­˜åœ¨ï¼Œè·³è¿‡")
            continue

        if not os.path.isdir(class_dir):
            print(f"   âš ï¸  è­¦å‘Šï¼šè·¯å¾„å­˜åœ¨ä½†ä¸æ˜¯ç›®å½•ï¼Œè·³è¿‡")
            continue

        found_classes.append(class_name)

        # è·å–è¯¥ç±»ç›®å½•ä¸‹çš„æ‰€æœ‰æ–‡ä»¶
        try:
            all_files = os.listdir(class_dir)
            print(f"   âœ“ ç›®å½•æœ‰æ•ˆï¼ŒåŒ…å« {len(all_files)} ä¸ªæ–‡ä»¶/æ–‡ä»¶å¤¹")
        except Exception as e:
            print(f"   âš ï¸  æ— æ³•è¯»å–ç›®å½•å†…å®¹: {e}")
            continue

        # æŸ¥æ‰¾å›¾åƒå’ŒNPYæ–‡ä»¶å¯¹
        img_extensions = ('.png', '.jpg', '.jpeg', '.bmp')
        image_files = [f for f in all_files if f.lower().endswith(img_extensions)]
        npy_files = [f for f in all_files if f.lower().endswith('.npy')]

        print(f"   - å›¾åƒæ–‡ä»¶æ•°: {len(image_files)}")
        print(f"   - NPYæ–‡ä»¶æ•°: {len(npy_files)}")

        # åŒ¹é…å›¾åƒå’ŒNPYæ–‡ä»¶å¯¹
        matched_count = 0
        for img_file in image_files:
            base_name = os.path.splitext(img_file)[0]
            npy_file = f"{base_name}.npy"

            img_path = os.path.join(class_dir, img_file)
            npy_path = os.path.join(class_dir, npy_file)

            if os.path.exists(npy_path):
                file_pairs.append((img_path, npy_path))
                labels_text.append(class_name)
                matched_count += 1
            else:
                # ä»…åœ¨ç¬¬ä¸€ä¸ªåŒ¹é…å¤±è´¥æ—¶æ‰“å°è¯¦ç»†ä¿¡æ¯
                if matched_count == 0:
                    print(f"   âš ï¸  ç¤ºä¾‹ï¼šæ‰¾åˆ°å›¾åƒ {img_file} ä½†ç¼ºå°‘å¯¹åº”çš„ NPY æ–‡ä»¶")

        print(f"   âœ“ æˆåŠŸåŒ¹é… {matched_count} å¯¹ image-npy æ–‡ä»¶")

    # æ€»ç»“
    print(f"\n{'=' * 80}")
    print(f"ğŸ“Š æ•°æ®åŠ è½½æ±‡æ€»:")
    print(f"   - æœŸæœ›ç±»åˆ«æ•°: {len(classes)}")
    print(f"   - æ‰¾åˆ°çš„ç±»åˆ«: {len(found_classes)} â†’ {found_classes}")
    print(f"   - æ€»æ ·æœ¬æ•°: {len(file_pairs)}")
    if file_pairs:
        print(f"   - ç±»åˆ«åˆ†å¸ƒ: {Counter(labels_text)}")
    print(f"{'=' * 80}\n")

    if not file_pairs:
        # æä¾›è¯¦ç»†çš„é”™è¯¯ä¿¡æ¯
        error_msg = f"âŒ åœ¨ {data_dir} ä¸­æœªæ‰¾åˆ°ä»»ä½•æœ‰æ•ˆçš„ image-npy æ–‡ä»¶å¯¹ã€‚\n"
        error_msg += f"   è¯·æ£€æŸ¥:\n"
        error_msg += f"   1. ç›®å½•ç»“æ„æ˜¯å¦æ­£ç¡®ï¼ˆæ¯ä¸ªç±»åˆ«åº”æœ‰å•ç‹¬çš„å­ç›®å½•ï¼‰\n"
        error_msg += f"   2. æ¯ä¸ªå›¾åƒæ–‡ä»¶æ˜¯å¦æœ‰å¯¹åº”çš„åŒå .npy æ–‡ä»¶\n"
        error_msg += f"   3. æ–‡ä»¶æ‰©å±•åæ˜¯å¦æ­£ç¡®ï¼ˆæ”¯æŒ: .png, .jpg, .jpeg, .bmpï¼‰\n"
        if all_subdirs:
            error_msg += f"   4. å®é™…å­ç›®å½•: {all_subdirs}\n"
            error_msg += f"   5. æœŸæœ›å­ç›®å½•: {classes}\n"
        raise ValueError(error_msg)

    return file_pairs, labels_text


def test_model(backbone_name):
    """
    Evaluate the specified model on the test set and return detailed metrics
    """
    print(f"\n{'#' * 100}")
    print(f"{'#' * 100}")
    print(f"æ­£åœ¨è¯„ä¼°æ¨¡å‹: {backbone_name}")
    print(f"{'#' * 100}")
    print(f"{'#' * 100}")

    model_path = Config.best_model_paths.get(backbone_name)
    if not model_path or not os.path.exists(model_path):
        print(f"âŒ é”™è¯¯ï¼šæ¨¡å‹æƒé‡æ–‡ä»¶ä¸å­˜åœ¨: {model_path}")
        print(f"   è·³è¿‡è¯¥æ¨¡å‹çš„è¯„ä¼°ã€‚")
        return None

    try:
        test_pairs, test_labels_text = load_data_from_folder(Config.test_data_root, Config.classes)
    except ValueError as e:
        print(f"âŒ åŠ è½½æµ‹è¯•æ•°æ®å¤±è´¥:\n{e}")
        print(f"   è·³è¿‡è¯¥æ¨¡å‹çš„è¯„ä¼°ã€‚")
        return None
    except Exception as e:
        print(f"âŒ åŠ è½½æµ‹è¯•æ•°æ®æ—¶å‘ç”ŸæœªçŸ¥é”™è¯¯: {e}")
        print(f"   è·³è¿‡è¯¥æ¨¡å‹çš„è¯„ä¼°ã€‚")
        return None

    label_encoder = LabelEncoder()
    label_encoder.fit(Config.classes)
    test_labels = label_encoder.transform(test_labels_text)

    print(f"âœ“ æµ‹è¯•æ•°æ®åŠ è½½æˆåŠŸ")
    print(f"  - æµ‹è¯•æ ·æœ¬æ•°: {len(test_labels)}")
    print(f"  - ç±»åˆ«åˆ†å¸ƒ: {Counter(test_labels_text)}")

    _, test_transform = get_transforms()
    npy_test_transform = transforms.Compose([
        transforms.Resize(Config.image_size, antialias=True)
    ])

    test_data = [(p[0], p[1], lbl) for p, lbl in zip(test_pairs, test_labels)]
    test_dataset = MultimodalDataset(test_data, transform=test_transform, npy_transform=npy_test_transform)
    test_loader = DataLoader(test_dataset, batch_size=Config.batch_size, num_workers=4, pin_memory=True)

    dummy_local_path = Config.local_pretrained_paths.get(backbone_name)
    model = ImprovedMultimodalModel(
        num_classes=len(Config.classes),
        backbone_name=backbone_name,
        local_pretrained_path=dummy_local_path
    )

    try:
        model.load_state_dict(torch.load(model_path, map_location=Config.device), strict=True)
        print(f"âœ“ æˆåŠŸåŠ è½½æ¨¡å‹æƒé‡: {model_path}")
    except RuntimeError as e:
        print(f"âŒ åŠ è½½æ¨¡å‹æƒé‡å¤±è´¥: {e}")
        return None
    except Exception as e:
        print(f"âŒ åŠ è½½æ¨¡å‹æƒé‡æ—¶å‘ç”ŸæœªçŸ¥é”™è¯¯: {e}")
        return None

    model.to(Config.device)
    model.eval()

    all_preds = []
    all_labels = []

    print(f"å¼€å§‹æ¨¡å‹æ¨ç†...")
    with torch.no_grad():
        for batch_idx, ((img, npy), labels) in enumerate(test_loader):
            img, npy, labels = img.to(Config.device), npy.to(Config.device), labels.to(Config.device)
            outputs = model((img, npy))
            _, predicted = torch.max(outputs.data, 1)

            all_preds.extend(predicted.cpu().numpy())
            all_labels.extend(labels.cpu().numpy())

            if (batch_idx + 1) % 10 == 0:
                print(f"  å·²å¤„ç† {(batch_idx + 1) * Config.batch_size} / {len(test_dataset)} ä¸ªæ ·æœ¬")

    # è®¡ç®—æ€»ä½“æŒ‡æ ‡
    precision = precision_score(all_labels, all_preds, average='macro', zero_division=0)
    recall = recall_score(all_labels, all_preds, average='macro', zero_division=0)
    f1 = f1_score(all_labels, all_preds, average='macro', zero_division=0)
    accuracy = accuracy_score(all_labels, all_preds)

    metrics = {
        "Accuracy": accuracy,
        "Precision": precision,
        "Recall": recall,
        "F1-Score": f1,
    }

    print(f"\nâœ“ æ¨¡å‹è¯„ä¼°å®Œæˆ:")
    print(f"  - Accuracy:  {accuracy:.4f}")
    print(f"  - Precision: {precision:.4f}")
    print(f"  - Recall:    {recall:.4f}")
    print(f"  - F1-Score:  {f1:.4f}")

    return metrics


def plot_training_metrics(log_files, metric_info, save_dir):
    """
    Plot training metrics curves with English labels
    """
    plt.style.use('seaborn-v0_8-whitegrid')
    plt.figure(figsize=(12, 8), dpi=300)

    main_metric_label = metric_info['main_label']
    save_filename = metric_info['filename']
    plot_keys = metric_info['keys']
    save_path = os.path.join(save_dir, save_filename)

    # ä½¿ç”¨é»˜è®¤å­—ä½“ï¼Œç¡®ä¿è‹±æ–‡æ­£å¸¸æ˜¾ç¤º
    plt.title(f'{main_metric_label} Curves for All Models', fontsize=18)
    plt.xlabel('Epoch', fontsize=14)
    plt.ylabel(main_metric_label, fontsize=14)

    plotted_models = 0
    for model_name, file_path in log_files.items():
        if os.path.exists(file_path):
            try:
                df = pd.read_csv(file_path)
                df.columns = df.columns.str.strip()
                epochs = df['epoch']
                for key, label in plot_keys.items():
                    if key in df.columns:
                        metric_values = df[key]
                        plt.plot(epochs, metric_values,
                                 label=f"{model_name} - {label}",
                                 linewidth=2)
                        plotted_models += 1
            except KeyError as e:
                print(f"âš ï¸  è­¦å‘Šï¼šè¯»å– {model_name} çš„æ—¥å¿—æ–‡ä»¶æ—¶ç¼ºå°‘å¿…éœ€çš„åˆ—: {e}")
                continue
            except Exception as e:
                print(f"âš ï¸  è­¦å‘Šï¼šè¯»å– {model_name} çš„æ—¥å¿—æ–‡ä»¶æ—¶å‘ç”Ÿé”™è¯¯: {e}")
                continue
        else:
            print(f"âš ï¸  è­¦å‘Šï¼šæ—¥å¿—æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")

    if plotted_models > 0:
        plt.legend(fontsize=12)
        plt.tight_layout()

        with PdfPages(save_path) as pdf:
            pdf.savefig()
        plt.close()
        print(f"âœ“ {main_metric_label} æ›²çº¿å·²ä¿å­˜è‡³: {save_path}")
    else:
        plt.close()
        print(f"âš ï¸  è­¦å‘Šï¼šæ²¡æœ‰å¯ç»˜åˆ¶çš„æ•°æ®ï¼Œè·³è¿‡ {main_metric_label} æ›²çº¿ç”Ÿæˆ")


if __name__ == "__main__":
    torch.manual_seed(Config.random_seed)
    np.random.seed(Config.random_seed)

    models_to_test = [
        'resnet34',
        'resnet50',
        'efficientnet_b0',
        'vit_base_patch16_224',
        'swin_tiny_patch4_window7_224',
        'convnext_tiny'
    ]

    log_files = {
        'ConvNeXt_Tiny': './results/result6/convnext_tiny/training_log_convnext_tiny.csv',
        'EfficientNet_B0': './results/result6/efficientnet_b0/training_log_efficientnet_b0.csv',
        'ResNet34': './results/result6/ResNet34/training_log_resnet34.csv',
        'ResNet50': './results/result6/ResNet50/training_log_resnet50.csv',
        'ViT_Base_Patch16_224': './results/result6/vit_base_patch16_224/training_log_vit_base_patch16_224.csv'
    }

    test_results = {}

    print("\n" + "=" * 100)
    print("å¼€å§‹æ¨¡å‹è¯„ä¼°æµç¨‹")
    print("=" * 100)

    for model_name in models_to_test:
        if ('vit' in model_name or 'swin' in model_name or
                'efficientnet' in model_name or 'convnext' in model_name):
            if timm is None:
                print(f"âš ï¸  è·³è¿‡ {model_name}ï¼šæœªå®‰è£… timm åº“")
                continue
        try:
            metrics = test_model(model_name)
            if metrics:
                test_results[model_name] = metrics
            else:
                test_results[model_name] = "Skipped"
        except Exception as e:
            print(f"âŒ æµ‹è¯• {model_name} æ—¶å‘ç”ŸæœªçŸ¥é”™è¯¯: {e}")
            import traceback

            traceback.print_exc()
            test_results[model_name] = "Error"

    print("\n" + "=" * 100)
    print("=" * 100)
    print("æœ€ç»ˆæµ‹è¯•ç»“æœæ±‡æ€»")
    print("=" * 100)
    print("=" * 100)

    for model_name, metrics in test_results.items():
        if isinstance(metrics, dict):
            print(f"\nâœ“ æ¨¡å‹: {model_name}")
            print(f"    Accuracy:  {metrics['Accuracy']:.4f}")
            print(f"    Precision: {metrics['Precision']:.4f}")
            print(f"    Recall:    {metrics['Recall']:.4f}")
            print(f"    F1-Score:  {metrics['F1-Score']:.4f}")
        else:
            print(f"\nâœ— æ¨¡å‹: {model_name} - è¯„ä¼°å¤±è´¥ ({metrics})")

    print("\n" + "=" * 100)
    print("å¼€å§‹ç»˜åˆ¶è®­ç»ƒæŒ‡æ ‡æ›²çº¿")
    print("=" * 100)

    # ç»˜åˆ¶å¹¶ä¿å­˜è®­ç»ƒå‡†ç¡®ç‡æ›²çº¿å›¾ (è‹±æ–‡)
    accuracy_metrics_to_plot = {
        'main_label': 'Training Accuracy',
        'filename': 'training_accuracy.pdf',
        'keys': {
            'train_accuracy': 'Training Accuracy',
        }
    }
    plot_training_metrics(log_files, accuracy_metrics_to_plot, Config.results_save_dir)

    # ç»˜åˆ¶å¹¶ä¿å­˜è®­ç»ƒæŸå¤±æ›²çº¿å›¾ (è‹±æ–‡)
    loss_metrics_to_plot = {
        'main_label': 'Training Loss',
        'filename': 'training_loss.pdf',
        'keys': {
            'train_loss': 'Training Loss',
        }
    }
    plot_training_metrics(log_files, loss_metrics_to_plot, Config.results_save_dir)

    print("\n" + "=" * 100)
    print("âœ“ æ‰€æœ‰ä»»åŠ¡å®Œæˆï¼")
    print("=" * 100)